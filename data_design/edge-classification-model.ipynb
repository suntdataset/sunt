{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287ba1fc-4740-4cd1-a483-387f4469059d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_undirected, train_test_split_edges\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f63c6feb-b536-4e82-a34d-7a99745e5679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear\n",
    "from torch import Tensor\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d33e5f-d862-47e2-ae46-b463a0cca7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# validartion\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de68c927-6228-417c-a97f-80a9c26bdae8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c817e451-bb3d-40d4-8c7a-10150009e9d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pre_processing(df_graph, \n",
    "                   df_features, \n",
    "                   col_features,\n",
    "                   col_target='severity'):\n",
    "    # create node\n",
    "    df_features['node'] = np.arange(0, df_features.shape[0])\n",
    "\n",
    "    # select graph with same node features\n",
    "    nodes_of_features = list(df_features.leg_pos.unique())\n",
    "    df_graph_subsample = df_graph.query(\" pos1 in @nodes_of_features and pos2 in @nodes_of_features \")\n",
    "    \n",
    "    # sync nodes\n",
    "    df_graph_subsample['src'] = pd.NA\n",
    "    df_graph_subsample['dst'] = pd.NA\n",
    "    for i in tqdm(range(df_features.shape[0])):\n",
    "        node_emb, node = df_features[['leg_pos', 'node']].values[i]\n",
    "        df_graph_subsample['src'][df_graph_subsample.query(f\" pos1 == '{node_emb}' \").index] = node\n",
    "        df_graph_subsample['dst'][df_graph_subsample.query(f\" pos2 == '{node_emb}' \").index] = node\n",
    "\n",
    "    print(df_graph_subsample.info())\n",
    "    # subsample graph\n",
    "    df_graph_subsample = df_graph_subsample.astype({'src': int, 'dst': int})\n",
    "    # \n",
    "    # define x features and target\n",
    "    #col_features = ['relSESA','consurf_old']\n",
    "    # \n",
    "    pos = df_features.leg_pos.values\n",
    "    x = torch.tensor(df_features[col_features].values,  dtype=torch.float)\n",
    "    #y = torch.tensor(df_features[col_target].values, dtype=torch.long)\n",
    "    # index of graph\n",
    "    _edge_index = torch.tensor(df_graph_subsample[['src', 'dst']].values, dtype=torch.long)\n",
    "    \n",
    "    # encoder target\n",
    "    encoder = LabelEncoder()\n",
    "    df_graph_subsample[col_target] = encoder.fit_transform(df_graph_subsample[col_target].values).astype(float)\n",
    "    \n",
    "    edge_labels = torch.tensor(df_graph_subsample[col_target].values, dtype=torch.long)\n",
    "    # weigths edges\n",
    "    edge_w = torch.tensor(df_graph_subsample['weight'].values, dtype=torch.float)\n",
    "\n",
    "    return x, edge_labels, _edge_index, edge_w, pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d46d4201-40e0-49c1-9671-2b62511e57c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df_features.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_281815/3080117273.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_features.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'df_edges.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'ponto'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'leg_pos'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_nullable_dtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m     )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, use_nullable_dtypes, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filesystem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         )\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         handles = get_handle(\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m         \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df_features.parquet'"
     ]
    }
   ],
   "source": [
    "df_v = pd.read_parquet('df_features.parquet')\n",
    "df_e = pd.read_parquet('df_edges.parquet')\n",
    "\n",
    "df_v = df_v.drop(['vm', 'target'], axis=1)\n",
    "df_v = df_v.rename({'ponto': 'leg_pos'}, axis=1)\n",
    "df_v = df_v.astype({'leg_pos': str})\n",
    "df_e = df_e.drop(['vm_edge'], axis=1)\n",
    "df_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e16a125-e667-4666-8d02-f5da96791127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f_selected = ['carregamento', 'desce', 'linha', 'sobe', 'trip_id', 'veiculo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a7e05-6e10-4908-9f5f-74842b80f1f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_e.head()\n",
    "df_e = df_e.rename({'src': 'pos1', 'dst': 'pos2', 'loader': 'weight'}, axis=1)\n",
    "df_e = df_e.astype({'pos1': str, 'pos2': str})\n",
    "df_e.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f31111-4acb-46fb-a8d1-062757541a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xa, edge_labelsa, edge_indexa, edge_wa, posa =  pre_processing(df_e, \n",
    "                                                              df_v, \n",
    "                                                              f_selected,\n",
    "                                                              col_target='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e3399a-018e-4acc-af92-3b2ced8be24b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure the graph is undirected\n",
    "#edge_index = to_undirected(edge_indexa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc76d88c-cc42-446f-a5fd-287ff29d0368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_labelsa.shape, edge_indexa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f328e4e-1537-427f-87fb-b84e3b58f467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_labelsa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74508bc-9d58-4ee8-84bf-4845c600404f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "edge_labels_oh = torch.nn.functional.one_hot(edge_labelsa)\n",
    "edge_labels_oh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea57b10-1550-4fea-bb00-238adde9aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_labels_oh = edge_labels_oh.float()\n",
    "edge_labels_oh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb130036-5a2c-4d75-abe5-1a5cda80d56d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = Data(x=xa, \n",
    "            edge_index=edge_indexa.t().contiguous())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892da032-249e-48d8-b774-ecf0941369b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb6c70d-9aa7-4f9f-ac5b-31d426888439",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split edges into train and test sets\n",
    "data = train_test_split_edges(data, val_ratio=0.0, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9372e142-f357-449a-84cd-d5a151477bdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456a5be-0d5b-4c59-98bc-5dd058cb88c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(data.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e930f2-0ce8-41f7-97c4-a5cbe22f1443",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract train and test edge indices and labels\n",
    "train_edge_index = data.train_pos_edge_index\n",
    "test_edge_index = data.test_pos_edge_index\n",
    "\n",
    "# For simplicity, use the same labels for train and test (replace with actual labels if available)\n",
    "train_edge_labels = edge_labels_oh[:train_edge_index.size(1)]\n",
    "test_edge_labels  = edge_labels_oh[:test_edge_index.size(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75c86d-7005-4ff5-95b6-19e7aaadb0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f45cc8-5032-4cbd-93e7-7b85508f6f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCNEdgeClassifier(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_channels, \n",
    "                 hidden_channels, \n",
    "                 out_channels, \n",
    "                 edge_hidden_dim, \n",
    "                 num_edge_classes):\n",
    "        \n",
    "        super(GCNEdgeClassifier, self).__init__()\n",
    "        # vertex\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        \n",
    "        # MLP to \n",
    "        self.fc1 = torch.nn.Linear(out_channels*2, edge_hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(edge_hidden_dim, num_edge_classes)\n",
    "        \n",
    "    def encoder(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "        \n",
    "    def decoder(self, node_embeddings, edge_index):\n",
    "        src, tgt = edge_index\n",
    "        edge_features = torch.cat((node_embeddings[src], node_embeddings[tgt]), dim=1)\n",
    "        \n",
    "        x = self.fc1(edge_features)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        z = self.encoder(x, edge_index)\n",
    "        \n",
    "        out = self.decoder(z, edge_index)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98cab69-5bda-4475-8bfe-ec68c54a7e86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "in_channels = data.x.shape[1]\n",
    "hidden_channels = 16\n",
    "node_embedding_dim = 16\n",
    "edge_hidden_dim = 8\n",
    "num_edge_classes = edge_labels_oh.shape[1]  # Example: binary classification\n",
    "\n",
    "# Initialize model\n",
    "model = GCNEdgeClassifier(in_channels, \n",
    "                  hidden_channels, \n",
    "                  node_embedding_dim, \n",
    "                  edge_hidden_dim, \n",
    "                  num_edge_classes)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212d209-b384-4f2a-8550-a31078dfdf64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "scores = []\n",
    "for epoch in tqdm(range(500)):  # Number of epochs\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass through GCN to get node embeddings\n",
    "    train_edge_predictions = model(data.x, train_edge_index)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = F.cross_entropy(train_edge_predictions, train_edge_labels)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    scores.append(loss.item())\n",
    "\n",
    "    #print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "\n",
    "print(f'Training completed with init loss {scores[0]} and last loss: {scores[-1]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835a1da3-bcc4-4f05-84ec-65fed8057bdb",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12410e2-3f7b-4202-b9de-d153197fc5d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "#edge_classifier.eval()\n",
    "\n",
    "# Forward pass through GCN to get node embeddings\n",
    "test_edge_predictions = model(data.x, test_edge_index)\n",
    "\n",
    "# Get edge features from node embeddings for test edges\n",
    "#test_edge_features = get_edge_features(node_embeddings, test_edge_index)\n",
    "\n",
    "# Classify test edges\n",
    "#test_edge_predictions = edge_classifier(test_edge_features)\n",
    "\n",
    "y_true = test_edge_labels.argmax(dim=1)\n",
    "y_pred = test_edge_predictions.argmax(dim=1)\n",
    "\n",
    "# Example evaluation metric: accuracy\n",
    "correct = (y_pred == y_true).sum()\n",
    "accuracy = int(correct) / test_edge_labels.size(0)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764197a1-681c-4f55-86b2-cad18f8e8577",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Compute MCC\n",
    "mcc = matthews_corrcoef(y_true, y_pred)\n",
    "print(\"MCC:\", mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a55d0-f3f6-4aac-8d5d-323aa4602689",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Counter(y_true.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a8c14b-05d3-4419-b0e9-09a5d8ba71d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a heatmap plot of the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, \n",
    "            fmt='d', cmap='Blues', \n",
    "            xticklabels=['0', '1', '2', '3'], \n",
    "            yticklabels=['0', '1', '2', '3'])\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('Actual Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd555a-b87c-43bf-afab-c6dcf30799d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
